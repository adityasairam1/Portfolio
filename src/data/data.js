export const personalInfo = {
  name: "Aditya Sairam Pullabhatla",
  title: "Software Engineer",
  location: "Detroit Metropolitan Area",
  phone: "+1 (216) 413-2548",
  email: "adityapsairam@gmail.com",
  linkedin: "https://www.linkedin.com/in/adityasairam/",
  github: "https://github.com/adityasairam1",
  summary: "Aditya Sairam Pullabhatla, Software Engineer",
  resumeUrl: "/Resume.pdf",
  profileImage: "/Profile.JPG"
};

export const experience = [
  {
    id: 1,
    company: "Robotics Technologies LLC",
    position: "Software Engineer",
    location: "Duncanville, TX",
    startDate: "Mar 2025",
    endDate: "Present",
    type: "Full-time",
    achievements: [
      "Architected distributed job scheduling system reducing processing time by 40%",
      "Developed real-time monitoring dashboard using React and WebSocket connections",
      "Implemented automated testing pipeline reducing deployment time by 60%",
      "Led migration of legacy C++ systems to modern cloud-based architecture",
      "Mentored junior developers and established coding standards"
    ],
    technologies: ["C++", "React", "Node.js", "AWS", "Docker", "PostgreSQL"]
  },
  {
    id: 2,
    company: "UMEE",
    position: "Mobile Software Engineer",
    location: "Remote",
    startDate: "Feb 2025",
    endDate: "June 2025",
    type: "Part-time",
    achievements: [
      "Developed cross-platform mobile applications using React Native",
      "Implemented real-time data synchronization and offline capabilities",
      "Optimized app performance reducing load time by 30%",
      "Collaborated with design team to implement user-friendly interfaces",
      "Integrated third-party APIs and payment gateways"
    ],
    technologies: ["React Native", "JavaScript", "Redux", "Firebase", "REST APIs"]
  },
  {
    id: 3,
    company: "Cleveland State University",
    position: "Graduate Research Assistant",
    location: "Cleveland, OH",
    startDate: "Aug 2023",
    endDate: "Dec 2024",
    type: "Part-time",
    achievements: [
      "Researched distributed computing algorithms for IoT sensor networks",
      "Developed machine learning models for predictive maintenance",
      "Published research paper on edge computing optimization",
      "Collaborated with industry partners on real-world applications"
    ],
    technologies: ["Python", "TensorFlow", "Kubernetes", "MongoDB", "REST APIs"]
  },
  {
    id: 4,
    company: "Amazon",
    position: "Data Catalog Engineer",
    location: "Chennai, India",
    startDate: "Jun 2021",
    endDate: "Dec 2022",
    type: "Full-time",
    achievements: [
      "Designed and implemented data catalog systems for large-scale data management",
      "Built automated data discovery and lineage tracking tools",
      "Optimized data processing pipelines improving efficiency by 45%",
      "Collaborated with data scientists and analysts to improve data accessibility",
      "Implemented data governance policies and compliance frameworks"
    ],
    technologies: ["Python", "Apache Spark", "AWS Glue", "S3", "Lambda", "DynamoDB"]
  },
  {
    id: 5,
    company: "Pyramid SoftSol",
    position: "Software Engineer",
    location: "Hyderabad, India",
    startDate: "May 2020",
    endDate: "May 2021",
    type: "Full-time",
    achievements: [
      "Developed enterprise web applications using modern JavaScript frameworks",
      "Implemented microservices architecture for scalable applications",
      "Created automated testing suites achieving 95% code coverage",
      "Led a team of 3 junior developers on multiple projects",
      "Optimized database performance reducing query time by 50%"
    ],
    technologies: ["JavaScript", "Node.js", "React", "MongoDB", "Docker", "Kubernetes"]
  },
  {
    id: 6,
    company: "Electronics Corporation of India Limited (ECIL)",
    position: "Machine Learning Engineer",
    location: "Hyderabad, India",
    startDate: "May 2019",
    endDate: "June 2020",
    type: "Internship",
    achievements: [
      "Developed machine learning models for industrial automation systems",
      "Implemented computer vision algorithms for quality control processes",
      "Created predictive maintenance models reducing equipment downtime by 25%",
      "Collaborated with hardware engineers to integrate ML solutions",
      "Presented research findings to senior management and stakeholders"
    ],
    technologies: ["Python", "TensorFlow", "OpenCV", "Scikit-learn", "Pandas", "NumPy"]
  }
];

export const skills = {
  "Programming Languages": [
    { name: "C", level: 95 },
    { name: "C++", level: 90 },
    { name: "Java", level: 85 },
    { name: "Python", level: 80 },
    { name: "SQL", level: 75 },
    { name: "Bash", level: 70 }
  ],
  "Systems Programming": [
    { name: "UNIX/Linux", level: 90 },
    { name: "Multi-threading", level: 85 },
    { name: "IPC", level: 80 },
    { name: "Socket Programming", level: 75 }
  ],
  "Web Technologies": [
    { name: "React", level: 85 },
    { name: "Node.js", level: 80 },
    { name: "JavaScript", level: 85 },
    { name: "HTML/CSS", level: 90 },
    { name: "REST APIs", level: 85 }
  ],
  "Cloud & DevOps": [
    { name: "AWS", level: 80 },
    { name: "Docker", level: 75 },
    { name: "Kubernetes", level: 70 },
    { name: "CI/CD", level: 75 },
    { name: "Git", level: 90 }
  ],
  "Databases": [
    { name: "PostgreSQL", level: 80 },
    { name: "MongoDB", level: 75 },
    { name: "MySQL", level: 85 },
    { name: "Redis", level: 70 }
  ],
  "Tools & Frameworks": [
    { name: "Spring Boot", level: 80 },
    { name: "TensorFlow", level: 70 },
    { name: "Docker", level: 75 },
    { name: "Jenkins", level: 70 },
    { name: "JUnit", level: 85 }
  ]
};

export const certifications = [
  {
    id: 1,
    name: "AWS Certified Cloud Practitioner",
    issuer: "Amazon Web Services",
    date: "Dec 2024",
    description: "Scalable cloud architecture, distributed systems, and AWS services",
    credentialId: "AWS-CCP-2024-001",
    url: "https://aws.amazon.com/certification/certified-cloud-practitioner/"
  },
  {
    id: 2,
    name: "Google Cloud Professional Developer",
    issuer: "Google Cloud",
    date: "Nov 2024",
    description: "Cloud-native application development and microservices architecture",
    credentialId: "GCP-PD-2024-002",
    url: "https://cloud.google.com/certification/cloud-developer"
  },
  {
    id: 3,
    name: "Certified Kubernetes Application Developer",
    issuer: "Cloud Native Computing Foundation",
    date: "Oct 2024",
    description: "Kubernetes application development and container orchestration",
    credentialId: "CKAD-2024-003",
    url: "https://www.cncf.io/certification/ckad/"
  }
];

export const education = [
  {
    id: 1,
    degree: "Master's in Computer Science",
    institution: "Cleveland State University",
    location: "Cleveland, OH",
    startDate: "Aug 2023",
    endDate: "Dec 2024",
    gpa: "3.8/4.0",
    courses: [
      "Advanced Database Systems",
      "Cloud Computing",
      "Data Management",
      "Database Optimization",
      "Software Engineering",
      "Algorithms",
      "Distributed Systems",
      "Computer Architecture",
      "Cryptography & Network Security"
    ],
    achievements: [
      "Dean's List for 3 consecutive semesters",
      "Research Assistant for IoT and Edge Computing Lab",
      "Published paper on distributed computing optimization"
    ]
  },
  {
    id: 2,
    degree: "Bachelor's in Computer Science",
    institution: "Jawaharlal Nehru Technological University Hyderabad",
    location: "Hyderabad, India",
    startDate: "Aug 2019",
    endDate: "May 2023",
    gpa: "3.6/4.0",
    courses: [
      "Data Structures and Algorithms",
      "Network-Based Application Development",
      "Cloud Computing",
      "Database Management Systems",
      "Operating Systems",
      "Computer Architecture",
      "Information Security"
    ],
    achievements: [
      "Graduated with Honors",
      "President of Computer Science Club",
      "Led team to win national coding competition"
    ]
  }
];

export const projects = [
  {
    id: 1,
    title: "Medline Medical Search Engine: AI-Powered Information Retrieval System",
    description: "Developed a sophisticated medical information retrieval system that scraped, processed, and indexed 4,500+ medical articles from MedlinePlus, creating a production-ready search engine with advanced Natural Language Processing (NLP) and machine learning algorithms. The system processes 1.4+ million terms using TF-IDF weighting and cosine similarity ranking to deliver highly relevant medical information through an intuitive web interface.",
    image: "/projects/medline-search-engine.jpg",
    technologies: ["Node.js", "JavaScript", "Puppeteer", "MongoDB", "MySQL", "Next.js", "React", "Lemmatizer", "Stem-Porter", "Express", "HTML5", "CSS3", "RESTful APIs"],
    features: [
      "Scraped and processed 4,500+ medical articles from MedlinePlus using Puppeteer automation",
      "Built hybrid database architecture with MongoDB (NoSQL) and MySQL (relational) storage",
      "Implemented advanced NLP pipeline with tokenization, lemmatization, and stemming",
      "Created inverted index with 1.4+ million term-document pairs and 36,256 unique dictionary entries",
      "Developed TF-IDF scoring and cosine similarity ranking for sub-second query response"
    ],
    github: "https://github.com/adityasairam1/medline-search-engine",
    demo: "https://medline-search.example.com",
    category: "AI/ML & Information Retrieval",
    status: "Completed"
  },
  {
    id: 2,
    title: "Comprehensive Data Processing Ecosystem: From Web Scraping to Distributed Computing",
    description: "Developed an end-to-end big data processing ecosystem demonstrating expertise across the entire data engineering lifecycleâ€”from data acquisition and ETL to distributed computing and advanced analytics. Processed over 100GB of data across various formats using both relational (SQL Server) and NoSQL (MongoDB) databases, culminating in distributed processing with Hadoop MapReduce and Apache Hive.",
    image: "/projects/big-data-ecosystem.jpg",
    technologies: ["Python", "Hadoop", "Apache Hive", "MongoDB", "SQL Server", "BeautifulSoup", "NLTK", "Flask", "MapReduce", "HDFS", "YARN", "Pandas", "Linux"],
    features: [
      "Phase 1: Web scraping 100+ historical State of Union addresses with BeautifulSoup",
      "Phase 2: XML data transformation pipeline with complex hierarchical parsing",
      "Phase 3: NoSQL analytics on 53GB+ Yelp data using MongoDB aggregation framework",
      "Phase 4: Information retrieval system with TF-IDF scoring and cosine similarity",
      "Phase 5: Distributed computing with Hadoop MapReduce and Apache Hive analytics"
    ],
    github: "https://github.com/adityasairam1/big-data-ecosystem",
    demo: "https://bigdata-demo.example.com",
    category: "Big Data Engineering",
    status: "Completed"
  },
  {
    id: 3,
    title: "Distributed Data Store with Replication System",
    description: "Built a fault-tolerant distributed data storage system featuring four replica servers that maintain data consistency through reliable UDP-based communication. Implemented READ/WRITE operations with MD5 integrity verification and automatic replication across peer servers.",
    image: "/projects/distributed-datastore.jpg",
    technologies: ["C", "UDP Networking", "OpenSSL", "MD5 Hashing", "Distributed Systems"],
    features: [
      "Reliable broadcast protocol with automatic retry mechanisms",
      "MD5-based data integrity verification",
      "Real-time peer-to-peer replication across distributed servers",
      "Hostname resolution and dynamic peer discovery"
    ],
    github: "https://github.com/adityasairam1/distributed-datastore",
    demo: "https://datastore-demo.example.com",
    category: "Distributed Systems",
    status: "Completed"
  },
  {
    id: 4,
    title: "Load-Balanced RPC Job Distribution System",
    description: "Developed a client-server simulation platform that intelligently distributes computational jobs across multiple servers using RPC. Implemented dynamic load balancing with real-time CPU monitoring from /proc/loadavg, automatic job migration, and adaptive threshold-based scheduling.",
    image: "/projects/rpc-loadbalancer.jpg",
    technologies: ["C", "RPC", "Multi-processing", "CPU Monitoring", "Linux System Programming"],
    features: [
      "Dynamic CPU load monitoring with configurable high/low thresholds",
      "Automatic job killing and resubmission based on server load",
      "Interactive command interface for job management and server control",
      "Fork-based parallel job execution with isolated process management"
    ],
    github: "https://github.com/adityasairam1/rpc-loadbalancer",
    demo: "https://loadbalancer-demo.example.com",
    category: "Systems Programming",
    status: "Completed"
  },
  {
    id: 5,
    title: "Virtual Memory Manager with LRU Page Replacement",
    description: "Created a memory management system simulating OS-level virtual-to-physical address translation with a two-part architecture: static page tables for basic translation and dynamic page tables with LRU-based page replacement.",
    image: "/projects/virtual-memory.jpg",
    technologies: ["C", "Memory Management", "Data Structures", "LRU Algorithm", "MD5 Verification"],
    features: [
      "Part 1: Static page table with direct address translation",
      "Part 2: Dynamic page table with LRU page replacement algorithm",
      "Physical frame management with optimal eviction policies",
      "Comprehensive page fault tracking and performance metrics"
    ],
    github: "https://github.com/adityasairam1/virtual-memory-manager",
    demo: "https://memory-demo.example.com",
    category: "Operating Systems",
    status: "Completed"
  },
  {
    id: 6,
    title: "Custom Read-Write Lock for User-Space Threading",
    description: "Implemented a custom Read-Write Lock (rwlock) for the SThreads user-space threading library, enabling concurrent reader access while ensuring exclusive writer access. Designed thread queues for fairness, atomic test-and-set operations for race condition prevention.",
    image: "/projects/rwlock.jpg",
    technologies: ["C", "Thread Synchronization", "Mutual Exclusion", "SThreads Library", "Concurrent Programming"],
    features: [
      "Multiple concurrent readers with exclusive writer access",
      "Thread queuing system ensuring fairness and proper scheduling",
      "Atomic operations preventing race conditions and busy-waiting",
      "Non-blocking try-lock implementation for flexible locking strategies"
    ],
    github: "https://github.com/adityasairam1/custom-rwlock",
    demo: "https://rwlock-demo.example.com",
    category: "Concurrent Programming",
    status: "Completed"
  }
];

export const socialLinks = [
  {
    name: "LinkedIn",
    url: "https://www.linkedin.com/in/adityasairam/",
    icon: "FaLinkedin",
    color: "text-blue-600"
  },
  {
    name: "GitHub",
    url: "https://github.com/adityasairam1",
    icon: "FaGithub",
    color: "text-gray-800 dark:text-gray-200"
  },
  {
    name: "Email",
    url: "mailto:adityapsairam@gmail.com",
    icon: "FaEnvelope",
    color: "text-red-600"
  },
  {
    name: "Phone",
    url: "tel:+12164132548",
    icon: "FaPhone",
    color: "text-green-600"
  }
];

export const navigation = [
  { name: "Home", href: "#home" },
  { name: "About", href: "#about" },
  { name: "Experience", href: "#experience" },
  { name: "Skills", href: "#skills" },
  { name: "Projects", href: "#projects" },
  { name: "Education", href: "#education" },
  { name: "Contact", href: "#contact" }
];

export const stats = [
  { label: "Years of Experience", value: "4+" },
  { label: "Projects Completed", value: "10+" },
  { label: "Technologies Mastered", value: "15+" },
  { label: "Certifications", value: "4+" }
];
